{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification Using HuggingFace Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ticb2QtlIHoo",
        "4kI_YPV2JopN",
        "8J9dzlB-M5o5",
        "49dnmi9pI008",
        "C7nV70cKMxYA",
        "vE8JUBXhNQY-",
        "CjptyKQwNZcK",
        "NIOZDfHyNfS6",
        "cX8C2rmWOFKY"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c24494b507d4e1aa9445a4c516fe55e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03de45231f534e49a0f06031c5e6eb7b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d62e513ed4d40bdbc1dd554e1ac66b4",
              "IPY_MODEL_c691fda0a53f4f6ca673403914ab666d"
            ]
          }
        },
        "03de45231f534e49a0f06031c5e6eb7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d62e513ed4d40bdbc1dd554e1ac66b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_242976ebc9f147619a690bbeda31509d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdb88fe6e4754ee58e1c033cfc3cf383"
          }
        },
        "c691fda0a53f4f6ca673403914ab666d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b6797869df204c189e40e74e19e1a1ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:00&lt;00:00, 703B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51a43cd2dcb54e7bb079758df5a6b23b"
          }
        },
        "242976ebc9f147619a690bbeda31509d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdb88fe6e4754ee58e1c033cfc3cf383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6797869df204c189e40e74e19e1a1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51a43cd2dcb54e7bb079758df5a6b23b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd1dcf3c577a46eda98e7f5ac2d4aa47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_91d30bb08ffa4988bff7ff741b81a19b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_af5ded4f67b84c78a1de70808a7cddeb",
              "IPY_MODEL_aa3a4740df074f69b1147402da0b0971"
            ]
          }
        },
        "91d30bb08ffa4988bff7ff741b81a19b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af5ded4f67b84c78a1de70808a7cddeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9b2f51cc37f546ca8b0b9056ad720876",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_127f6fd5733a43f8982f484991e0f9bf"
          }
        },
        "aa3a4740df074f69b1147402da0b0971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4123baed6999422c935315513030da8a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:12&lt;00:00, 18.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5278b80d2e043c1935a716f0f13d28b"
          }
        },
        "9b2f51cc37f546ca8b0b9056ad720876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "127f6fd5733a43f8982f484991e0f9bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4123baed6999422c935315513030da8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5278b80d2e043c1935a716f0f13d28b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4eda285bf684810a3994130169ed9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6735997bb888475293f2dbeee9063999",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d049a593982b4a7c9c18e2bafb8ba8ad",
              "IPY_MODEL_8a69395eb8454f02b7fd75100bce33e1"
            ]
          }
        },
        "6735997bb888475293f2dbeee9063999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d049a593982b4a7c9c18e2bafb8ba8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d7285cb7011f401a97be025cc3917bd6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c93c7230871f48fbb8994a1cbe5ea75f"
          }
        },
        "8a69395eb8454f02b7fd75100bce33e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df63d22e94bf4e2e9f3182416ee87c30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:01&lt;00:00, 332kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9eec2e80ab947c1b73ae51b2dc863e4"
          }
        },
        "d7285cb7011f401a97be025cc3917bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c93c7230871f48fbb8994a1cbe5ea75f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df63d22e94bf4e2e9f3182416ee87c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9eec2e80ab947c1b73ae51b2dc863e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65cc9ae75dca431199d809fcf780e4eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c162381347054dd2952e494a4b692001",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_25b2a2608d7d445a9ae2747c6a0ccc54",
              "IPY_MODEL_5ab6d9a58e82436e8dac04ca318a1f3f"
            ]
          }
        },
        "c162381347054dd2952e494a4b692001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25b2a2608d7d445a9ae2747c6a0ccc54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2174b7e7949f4537bf635556ab598732",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19aed598db7c4d6a97fdf2445233faf1"
          }
        },
        "5ab6d9a58e82436e8dac04ca318a1f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55e879cfa1ea4482a1041f95d28937b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 245B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aeca3b894ed24098b2fe12225fa9f550"
          }
        },
        "2174b7e7949f4537bf635556ab598732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19aed598db7c4d6a97fdf2445233faf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55e879cfa1ea4482a1041f95d28937b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aeca3b894ed24098b2fe12225fa9f550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d70a0374589941e6aacc92544fda3a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a48e25bbe6b4ce2b174d9db61646b88",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f795c740aa9485ab574515eb1f689fb",
              "IPY_MODEL_37920d0419954e6f8a7bbf772d5a4b42"
            ]
          }
        },
        "0a48e25bbe6b4ce2b174d9db61646b88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f795c740aa9485ab574515eb1f689fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5666fe19dbdb47c7904b81e399db30f0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 363423424,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 363423424,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42521229932b409c8544523c4e555f02"
          }
        },
        "37920d0419954e6f8a7bbf772d5a4b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8523b68989cc46cf821a965dd37762e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 363M/363M [00:07&lt;00:00, 50.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec0f023809b04461bc5f47a777bfd2bb"
          }
        },
        "5666fe19dbdb47c7904b81e399db30f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42521229932b409c8544523c4e555f02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8523b68989cc46cf821a965dd37762e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec0f023809b04461bc5f47a777bfd2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S578cMEwo6oZ"
      },
      "source": [
        "#this notebook is am example of text classification using Huggingface models and fune tuning for Text classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yCdb7TJHXT5"
      },
      "source": [
        "# Check GPU Availability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55lUtZAF4zvz",
        "outputId": "434d161a-0e18-4e89-b7f7-e4424fbe45d7"
      },
      "source": [
        "import tensorflow as tf\n",
        "if tf.test.is_gpu_available():\n",
        "  print(tf.test.gpu_device_name())\n",
        "\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-68ef059cc236>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "/device:GPU:0\n",
            "Tue Jun  1 01:22:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0    27W /  70W |    222MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzOaRSHxqBvv"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl2A2eLzqJQM"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "## This notebook is am example of text classification using Huggingface models and fune tuning for Text classification. \n",
        "We will be using the below data set as given in the URL for Amazon Reviews Dataset\n",
        "URL: https://www.kaggle.com/bittlingmayer/amazonreviews\n",
        "\n",
        "Download the dataset and unzip the train and test txt files to use them for model\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4dJKQvT0wJC",
        "outputId": "f9192c51-915c-4b50-a579-9fe03073185f"
      },
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-01 01:22:11--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: â€˜aclImdb_v1.tar.gzâ€™\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  77.5MB/s    in 1.0s    \n",
            "\n",
            "2021-06-01 01:22:12 (77.5 MB/s) - â€˜aclImdb_v1.tar.gzâ€™ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYv9s6Zr01t3"
      },
      "source": [
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkWbHpCxwUjd",
        "outputId": "7f36f7cb-e728-44f9-d629-51f477ef4f3b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3MB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shDxHzS7HfNj"
      },
      "source": [
        "# Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBUOWOTnwUmf"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def read_imdb_split(split_dir):\n",
        "    split_dir = Path(split_dir)\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for label_dir in [\"pos\", \"neg\"]:\n",
        "        for text_file in (split_dir/label_dir).iterdir():\n",
        "            texts.append(text_file.read_text())\n",
        "            labels.append(0 if label_dir is \"neg\" else 1)\n",
        "\n",
        "    return texts, labels\n",
        "\n",
        "train_texts, train_labels = read_imdb_split('aclImdb/train')\n",
        "test_texts, test_labels = read_imdb_split('aclImdb/test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi36EqlcwUpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd6e594-7d32-44ab-b742-7cc2f88abf7b"
      },
      "source": [
        "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000, 25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPzUWGdJHmEo"
      },
      "source": [
        "## Split the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKQkihj0wUsC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAHR0kh6HtWd"
      },
      "source": [
        "## Prepare Encodings\n",
        "\n",
        "Load the Tokenizer as per the model and then prepare the dataset for train, test, val with encodings using the tokenizer. Returns a dict with:\n",
        "\n",
        "\n",
        "*   Input Ids\n",
        "*   Attention Masks\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjgqmFc2wUuJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253,
          "referenced_widgets": [
            "0c24494b507d4e1aa9445a4c516fe55e",
            "03de45231f534e49a0f06031c5e6eb7b",
            "3d62e513ed4d40bdbc1dd554e1ac66b4",
            "c691fda0a53f4f6ca673403914ab666d",
            "242976ebc9f147619a690bbeda31509d",
            "bdb88fe6e4754ee58e1c033cfc3cf383",
            "b6797869df204c189e40e74e19e1a1ff",
            "51a43cd2dcb54e7bb079758df5a6b23b",
            "fd1dcf3c577a46eda98e7f5ac2d4aa47",
            "91d30bb08ffa4988bff7ff741b81a19b",
            "af5ded4f67b84c78a1de70808a7cddeb",
            "aa3a4740df074f69b1147402da0b0971",
            "9b2f51cc37f546ca8b0b9056ad720876",
            "127f6fd5733a43f8982f484991e0f9bf",
            "4123baed6999422c935315513030da8a",
            "a5278b80d2e043c1935a716f0f13d28b",
            "f4eda285bf684810a3994130169ed9cd",
            "6735997bb888475293f2dbeee9063999",
            "d049a593982b4a7c9c18e2bafb8ba8ad",
            "8a69395eb8454f02b7fd75100bce33e1",
            "d7285cb7011f401a97be025cc3917bd6",
            "c93c7230871f48fbb8994a1cbe5ea75f",
            "df63d22e94bf4e2e9f3182416ee87c30",
            "e9eec2e80ab947c1b73ae51b2dc863e4",
            "65cc9ae75dca431199d809fcf780e4eb",
            "c162381347054dd2952e494a4b692001",
            "25b2a2608d7d445a9ae2747c6a0ccc54",
            "5ab6d9a58e82436e8dac04ca318a1f3f",
            "2174b7e7949f4537bf635556ab598732",
            "19aed598db7c4d6a97fdf2445233faf1",
            "55e879cfa1ea4482a1041f95d28937b8",
            "aeca3b894ed24098b2fe12225fa9f550"
          ]
        },
        "outputId": "36362269-eda8-42f3-945a-497431b64cc1"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c24494b507d4e1aa9445a4c516fe55e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd1dcf3c577a46eda98e7f5ac2d4aa47",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4eda285bf684810a3994130169ed9cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65cc9ae75dca431199d809fcf780e4eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgKA7rF01xDJ",
        "outputId": "7c187419-9f90-40f3-b6cc-d46cefe646fe"
      },
      "source": [
        "train_texts[0], tokenizer(train_texts[0]), len(tokenizer(train_texts[0])['input_ids'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('This is bar none the most hilarious movie I have ever seen. Beginning with the four delinquents being sent off by their fathers to Wienberg Military Academy, a tone is set that steadily continues all throughout this goofball film, and it does not let up for a second.<br /><br />It\\'s tough trying to describe this film; the humor elements are so spot on and brilliantly concieved that upon a first look it appears as nothing more than a stupid 80\\'s teen lust comedy. But it is oh so much more than that! Fresh from the minds of those folks over at MAD Magazine, Up the Academy serves up a formula and style that I have never since seen duplicated by ANY of the \"funniest\" offerings to come out of Hollywood in years past. Basically the film is so full of infantile cornball material that you might guess that the writers were a couple of 14 year olds themselves. See this movie if you love to act \"immature.\" A classic. *****',\n",
              " {'input_ids': [101, 2023, 2003, 3347, 3904, 1996, 2087, 26316, 3185, 1045, 2031, 2412, 2464, 1012, 2927, 2007, 1996, 2176, 3972, 2378, 15417, 2015, 2108, 2741, 2125, 2011, 2037, 11397, 2000, 22782, 4059, 2510, 2914, 1010, 1037, 4309, 2003, 2275, 2008, 11328, 4247, 2035, 2802, 2023, 27571, 26337, 8095, 2143, 1010, 1998, 2009, 2515, 2025, 2292, 2039, 2005, 1037, 2117, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2009, 1005, 1055, 7823, 2667, 2000, 6235, 2023, 2143, 1025, 1996, 8562, 3787, 2024, 2061, 3962, 2006, 1998, 8235, 2135, 9530, 23402, 7178, 2008, 2588, 1037, 2034, 2298, 2009, 3544, 2004, 2498, 2062, 2084, 1037, 5236, 3770, 1005, 1055, 9458, 11516, 4038, 1012, 2021, 2009, 2003, 2821, 2061, 2172, 2062, 2084, 2008, 999, 4840, 2013, 1996, 9273, 1997, 2216, 12455, 2058, 2012, 5506, 2932, 1010, 2039, 1996, 2914, 4240, 2039, 1037, 5675, 1998, 2806, 2008, 1045, 2031, 2196, 2144, 2464, 24473, 2094, 2011, 2151, 1997, 1996, 1000, 4569, 15580, 2102, 1000, 14927, 2000, 2272, 2041, 1997, 5365, 1999, 2086, 2627, 1012, 10468, 1996, 2143, 2003, 2061, 2440, 1997, 10527, 9463, 9781, 7384, 3430, 2008, 2017, 2453, 3984, 2008, 1996, 4898, 2020, 1037, 3232, 1997, 2403, 2095, 19457, 3209, 1012, 2156, 2023, 3185, 2065, 2017, 2293, 2000, 2552, 1000, 26838, 1012, 1000, 1037, 4438, 1012, 1008, 1008, 1008, 1008, 1008, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
              " 217)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qZ6kjl92LMq",
        "outputId": "21a61015-498f-41ca-f4ad-8a77729b8958"
      },
      "source": [
        "train_texts[0], tokenizer(train_texts[0]), len(tokenizer(train_texts[0], truncation=True, padding=True)['input_ids'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('This is bar none the most hilarious movie I have ever seen. Beginning with the four delinquents being sent off by their fathers to Wienberg Military Academy, a tone is set that steadily continues all throughout this goofball film, and it does not let up for a second.<br /><br />It\\'s tough trying to describe this film; the humor elements are so spot on and brilliantly concieved that upon a first look it appears as nothing more than a stupid 80\\'s teen lust comedy. But it is oh so much more than that! Fresh from the minds of those folks over at MAD Magazine, Up the Academy serves up a formula and style that I have never since seen duplicated by ANY of the \"funniest\" offerings to come out of Hollywood in years past. Basically the film is so full of infantile cornball material that you might guess that the writers were a couple of 14 year olds themselves. See this movie if you love to act \"immature.\" A classic. *****',\n",
              " {'input_ids': [101, 2023, 2003, 3347, 3904, 1996, 2087, 26316, 3185, 1045, 2031, 2412, 2464, 1012, 2927, 2007, 1996, 2176, 3972, 2378, 15417, 2015, 2108, 2741, 2125, 2011, 2037, 11397, 2000, 22782, 4059, 2510, 2914, 1010, 1037, 4309, 2003, 2275, 2008, 11328, 4247, 2035, 2802, 2023, 27571, 26337, 8095, 2143, 1010, 1998, 2009, 2515, 2025, 2292, 2039, 2005, 1037, 2117, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2009, 1005, 1055, 7823, 2667, 2000, 6235, 2023, 2143, 1025, 1996, 8562, 3787, 2024, 2061, 3962, 2006, 1998, 8235, 2135, 9530, 23402, 7178, 2008, 2588, 1037, 2034, 2298, 2009, 3544, 2004, 2498, 2062, 2084, 1037, 5236, 3770, 1005, 1055, 9458, 11516, 4038, 1012, 2021, 2009, 2003, 2821, 2061, 2172, 2062, 2084, 2008, 999, 4840, 2013, 1996, 9273, 1997, 2216, 12455, 2058, 2012, 5506, 2932, 1010, 2039, 1996, 2914, 4240, 2039, 1037, 5675, 1998, 2806, 2008, 1045, 2031, 2196, 2144, 2464, 24473, 2094, 2011, 2151, 1997, 1996, 1000, 4569, 15580, 2102, 1000, 14927, 2000, 2272, 2041, 1997, 5365, 1999, 2086, 2627, 1012, 10468, 1996, 2143, 2003, 2061, 2440, 1997, 10527, 9463, 9781, 7384, 3430, 2008, 2017, 2453, 3984, 2008, 1996, 4898, 2020, 1037, 3232, 1997, 2403, 2095, 19457, 3209, 1012, 2156, 2023, 3185, 2065, 2017, 2293, 2000, 2552, 1000, 26838, 1012, 1000, 1037, 4438, 1012, 1008, 1008, 1008, 1008, 1008, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
              " 217)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0F5zu4gwUwZ"
      },
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxJJuMHP3Nn2",
        "outputId": "180f3629-109e-4ba1-d3ad-17e923387c59"
      },
      "source": [
        "type(train_encodings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2OiueKs3358",
        "outputId": "f2a2d904-fbb7-42b0-bea7-84cbd74969a3"
      },
      "source": [
        "train_encodings.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ticb2QtlIHoo"
      },
      "source": [
        "## Prepare Datasets with Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGofE9MlwU9d"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    train_labels\n",
        "))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    val_labels\n",
        "))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    test_labels\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgjdrg6bwVAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d88699-f4ee-443c-b25c-8398ff732ecb"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ({input_ids: (512,), attention_mask: (512,)}, ()), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfzwBG7jwVFu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a67f8db-5247-40b5-fed2-5fcad38cde37"
      },
      "source": [
        "for x,y in train_dataset:\n",
        "  print(x,y)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
            "array([  101,  2023,  2003,  3347,  3904,  1996,  2087, 26316,  3185,\n",
            "        1045,  2031,  2412,  2464,  1012,  2927,  2007,  1996,  2176,\n",
            "        3972,  2378, 15417,  2015,  2108,  2741,  2125,  2011,  2037,\n",
            "       11397,  2000, 22782,  4059,  2510,  2914,  1010,  1037,  4309,\n",
            "        2003,  2275,  2008, 11328,  4247,  2035,  2802,  2023, 27571,\n",
            "       26337,  8095,  2143,  1010,  1998,  2009,  2515,  2025,  2292,\n",
            "        2039,  2005,  1037,  2117,  1012,  1026,  7987,  1013,  1028,\n",
            "        1026,  7987,  1013,  1028,  2009,  1005,  1055,  7823,  2667,\n",
            "        2000,  6235,  2023,  2143,  1025,  1996,  8562,  3787,  2024,\n",
            "        2061,  3962,  2006,  1998,  8235,  2135,  9530, 23402,  7178,\n",
            "        2008,  2588,  1037,  2034,  2298,  2009,  3544,  2004,  2498,\n",
            "        2062,  2084,  1037,  5236,  3770,  1005,  1055,  9458, 11516,\n",
            "        4038,  1012,  2021,  2009,  2003,  2821,  2061,  2172,  2062,\n",
            "        2084,  2008,   999,  4840,  2013,  1996,  9273,  1997,  2216,\n",
            "       12455,  2058,  2012,  5506,  2932,  1010,  2039,  1996,  2914,\n",
            "        4240,  2039,  1037,  5675,  1998,  2806,  2008,  1045,  2031,\n",
            "        2196,  2144,  2464, 24473,  2094,  2011,  2151,  1997,  1996,\n",
            "        1000,  4569, 15580,  2102,  1000, 14927,  2000,  2272,  2041,\n",
            "        1997,  5365,  1999,  2086,  2627,  1012, 10468,  1996,  2143,\n",
            "        2003,  2061,  2440,  1997, 10527,  9463,  9781,  7384,  3430,\n",
            "        2008,  2017,  2453,  3984,  2008,  1996,  4898,  2020,  1037,\n",
            "        3232,  1997,  2403,  2095, 19457,  3209,  1012,  2156,  2023,\n",
            "        3185,  2065,  2017,  2293,  2000,  2552,  1000, 26838,  1012,\n",
            "        1000,  1037,  4438,  1012,  1008,  1008,  1008,  1008,  1008,\n",
            "         102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0],\n",
            "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
            "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32)>} tf.Tensor(1, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kI_YPV2JopN"
      },
      "source": [
        "## Prepare Dataset with Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7tJMduIJyyh"
      },
      "source": [
        "import torch\n",
        "\n",
        "class IMDbDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset_torch = IMDbDataset(train_encodings, train_labels)\n",
        "val_dataset_torch = IMDbDataset(val_encodings, val_labels)\n",
        "test_dataset_torch = IMDbDataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NwKoJnIINqX"
      },
      "source": [
        "# With TF Trainer\n",
        "\n",
        "\n",
        "*   Load the SequenceClassification Model, Trainer and Training Argument objects from transformers\n",
        "\n",
        "*   Set the hyperparameters, Logs and Results Directory\n",
        "*   Start Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J9dzlB-M5o5"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ElODjh9wVIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544,
          "referenced_widgets": [
            "d70a0374589941e6aacc92544fda3a89",
            "0a48e25bbe6b4ce2b174d9db61646b88",
            "9f795c740aa9485ab574515eb1f689fb",
            "37920d0419954e6f8a7bbf772d5a4b42",
            "5666fe19dbdb47c7904b81e399db30f0",
            "42521229932b409c8544523c4e555f02",
            "8523b68989cc46cf821a965dd37762e0",
            "ec0f023809b04461bc5f47a777bfd2bb"
          ]
        },
        "outputId": "ee01d6b1-509a-4ee1-f582-2c7228667a62"
      },
      "source": [
        "from transformers import TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments\n",
        "\n",
        "training_args = TFTrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "with training_args.strategy.scope():\n",
        "    model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "trainer = TFTrainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset             # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d70a0374589941e6aacc92544fda3a89",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=363423424.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_transform', 'vocab_layer_norm', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'classifier', 'pre_classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f5670d7ce50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f5670d7ce50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f568c62cdd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f568c62cdd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49dnmi9pI008"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAVymXnTAMBB",
        "outputId": "93df952e-5d8e-4f50-aec6-a29d60c603c0"
      },
      "source": [
        "trainer.evaluate(val_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.23629227167443384}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXhCh0ErJQiR"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aduxHW4mAMFx",
        "outputId": "1ab3bc2c-a8b5-4fc4-bfbb-745a05ead2f2"
      },
      "source": [
        "trainer.predict(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[-3.4361587,  3.3285534],\n",
              "       [-2.477746 ,  2.4099193],\n",
              "       [-3.3440704,  3.2103994],\n",
              "       ...,\n",
              "       [ 1.6684272, -1.9207743],\n",
              "       [ 2.9769418, -3.5924716],\n",
              "       [ 3.0639277, -3.647531 ]], dtype=float32), label_ids=array([1, 1, 1, ..., 0, 0, 0], dtype=int32), metrics={'eval_loss': 0.22864768572170716})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG9YfahmAMI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f185e9-9955-4d72-ed8b-1b791eb9000d"
      },
      "source": [
        "output = trainer.predict(test_dataset)\n",
        "# output[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge7D1bqBbYGy",
        "outputId": "2c381ab0-9cc9-4176-f79b-818724bfd646"
      },
      "source": [
        "output[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-3.2797835,  2.8653524],\n",
              "        [-3.0618846,  2.669401 ],\n",
              "        [-3.3107646,  2.9197867],\n",
              "        ...,\n",
              "        [ 1.8857203, -2.4959643],\n",
              "        [ 2.8729527, -3.5769522],\n",
              "        [ 2.8872898, -3.6161554]], dtype=float32),\n",
              " array([1, 1, 1, ..., 0, 0, 0], dtype=int32),\n",
              " {'eval_loss': 0.22331083644076685})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIM1RuHJbdu-",
        "outputId": "0b726547-8ad7-4462-cfd3-713fc06457fc"
      },
      "source": [
        "output[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.2797835,  2.8653524],\n",
              "       [-3.0618846,  2.669401 ],\n",
              "       [-3.3107646,  2.9197867],\n",
              "       ...,\n",
              "       [ 1.8857203, -2.4959643],\n",
              "       [ 2.8729527, -3.5769522],\n",
              "       [ 2.8872898, -3.6161554]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvsmfvZwefXn"
      },
      "source": [
        "tf_predictions = tf.nn.sigmoid(output[0])\n",
        "tf_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV6AWV1WNIcH",
        "outputId": "ca5e50d2-c8eb-42c2-b475-8a93c928d6e7"
      },
      "source": [
        "predictions = tf.argmax(output[0], axis = 1)\n",
        "#predictions = tf.argmax(tf_predictions, axis = 1)\n",
        "predictions[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uxakPolVjvP",
        "outputId": "96c53a41-f19f-4f65-e6bd-711dc0c91aa1"
      },
      "source": [
        "label_ids_output = output[1]\n",
        "label_ids_output[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7nV70cKMxYA"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSy53fVpAMMJ"
      },
      "source": [
        "trainer.save_model(\"TF_senti_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tupt21MYHD8L"
      },
      "source": [
        "# With Pytorch Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE8JUBXhNQY-"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "9e4_tfV6AMPl",
        "outputId": "4a3fc157-7225-473f-f7c3-992e2c6a62b2"
      },
      "source": [
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "training_args_pt = TrainingArguments(\n",
        "    output_dir='./results_pt',          # output directory\n",
        "    num_train_epochs=1,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs_pt',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "model_pt = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "trainer_pt = Trainer(\n",
        "    model=model_pt,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args_pt,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset_torch,         # training dataset\n",
        "    eval_dataset=val_dataset_torch             # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer_pt.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-96028f8b8a80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args_pt\u001b[0m\u001b[0;34m,\u001b[0m                  \u001b[0;31m# training arguments, defined above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset_torch\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0;31m# training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset_torch\u001b[0m             \u001b[0;31m# evaluation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_model_on_device\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;31m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjptyKQwNZcK"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s1e1Ri4NL8j"
      },
      "source": [
        "trainer_pt.evaluate(val_dataset_torch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIOZDfHyNfS6"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD7rjwucNL_N"
      },
      "source": [
        "trainer_pt.predict(test_dataset_torch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUoOMjvNNMDA"
      },
      "source": [
        "predictions_pt = trainer_pt.predict(test_dataset_torch)\n",
        "predictions_pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET9xk4w_N-Gv"
      },
      "source": [
        "# With Native tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX8C2rmWOFKY"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5urPvtgdNMGi",
        "outputId": "7b61d0da-6db9-41a7-91b3-0953247cfcde"
      },
      "source": [
        "from transformers import TFDistilBertForSequenceClassification\n",
        "\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics = ['accuracy']) # can also use any keras loss fn\n",
        "hsitory = model.fit(train_dataset.shuffle(1000).batch(16), epochs=3, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_transform', 'vocab_layer_norm', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_79']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1250/1250 [==============================] - 1107s 880ms/step - loss: 0.2731 - accuracy: 0.8868\n",
            "Epoch 2/3\n",
            "1250/1250 [==============================] - 1100s 880ms/step - loss: 0.1445 - accuracy: 0.9486\n",
            "Epoch 3/3\n",
            "1250/1250 [==============================] - 1101s 880ms/step - loss: 0.0694 - accuracy: 0.9770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBh72HQ9NMJm",
        "outputId": "8909d0fb-9924-4db5-f837-afe8e0f3457a"
      },
      "source": [
        "hsitory.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.8867999911308289, 0.9485999941825867, 0.9769999980926514],\n",
              " 'loss': [0.2730958163738251, 0.14453208446502686, 0.06941771507263184]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "9VD4B9f_yIVF",
        "outputId": "f6c64aa7-510a-4e14-c8c4-f83c22f14f57"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "pd.DataFrame(hsitory.history).plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f51e1771990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfXRU9b3v8fc3k0kmzyTkkQQFFBGwihqtV1vFc2pFrWJ1edVbW5+Kt6fV5a1nHdujtp7bulY9dfXeXte1VW6vWm9PtdZqr61PR1q9tBWswSIqAUR8IBAgPJgAYfL4u3/MzmRnMkMmMJOHzee1Vlb2/PYvM99shg8/fvu395hzDhERmfxyxrsAERHJDAW6iEhAKNBFRAJCgS4iEhAKdBGRgMgdrxeurKx0M2bMGK+XFxGZlFatWrXTOVeVbN+4BfqMGTNoamoar5cXEZmUzOyjVPtGnHIxs4fNbIeZvZNiv5nZ/Wa20czWmNkph1OsiIgcmnTm0B8FFh1k/wXAbO/rJuCnh1+WiIiM1oiB7pxbDuw+SJfFwGMuZiUwxczqMlWgiIikJxOrXOqBzb7HLV7bMGZ2k5k1mVlTW1tbBl5aREQGjOmyRefcUudco3Ousaoq6UlaERE5RJkI9C3AdN/jBq9NRETGUCYC/VngK95qlzOAdudcawaeV0RERmHEdehm9jiwEKg0sxbgbiAM4Jx7EHgeuBDYCHQC12erWBGRCaevF3o6fV8HoLvz4G3HnQ/1p2a8lBED3Tl39Qj7HfCNjFUkIpIp/f3QG00I1v2x74fUliSo+7pHX1dxzfgEuohIVjgHfT3QMxCc/hA9nDZf2PZ0jr6uUB6ECyBc5H0vhLzC2HZhpddWAHlFCf1G0WaW+eOJAl1EUunvGxqQ3Z0JgdnpG7Gm0y/JCNj1jbIo8wVkofflhWZx9WDbQADH+4yiLTR5Y3HyVi5yJHMOertSBOv+hOmBVG0jhHJf1+jryo0kD9tIKZTUDm0bGK0OjFxTBbW/LTc/a6PbIFCgi2RDX68vRH3TAqNuO0goM8rPA7ZQitAshIIpw9v8j+Oj2cKD98sJZeVwSnoU6CLOQfQT2L8T9u2Azl1euCaMXIecEPO3JQnb/p7R15GbIkgLK1KMZEfZFgprdBtwCnQJpr7eWDDvb4P9OwbDOtn2/raRVyrkhH1h6w/NQiiqZMioNy8hkIeNbpOMeHMjkKPPm5HDo0CXyaMnOhjQ+9oOvt25i6RTEjnh2Mmzokooqobq+VBcFdsuqoptF1bGRrf+6YlQeMx/XZHRUqDL+HEOujoSRsxtXignbu+M9U0mrzgWxkVVMPUYOOrTsYD2B/fAdmSKph0ksBTokln9fdC5O/2RdKqVFAUV3oi5GuoWDI6e4yPp6sEQzysc299RZIJSoMvIeru8IE42ek6c6tgJrn/4c+TkegHsjZirjh8+eh7YLpyqKQ6RQ6BAPxI5B937vGmOnV4g+7YTgzvanvx5woWDo+Tyo6GhcfjoeWA7MkUn/USyTIEeFP39cGCPL5BThPXASLr3QPLniUwZDOGaE5KH88BXfvHY/o4iclAK9ImsryfFVMeOJO07k19GbaHB6YyiSph6bPKALq6Ore7IzRv731NEMkKBPta69x9k9JywHf0k+XPkRrz55iooq4dpC4aPnourY30KyjXVIXKEUKAfLue8qY62JKPnJNup7v6WXza4iqPqeJh5duqRdF6xlt6JyDAK9GT6emOrNVKFc+Lj/t7hz2E5sdUaA1Md008f3B4YPce3q2I3HRIROQxHTqD3HBh59DywfWB38ucI5Q1OdZTUQu2J3qi6arB9YLuwQjcqEpExNXkD3bnYcrqRRs8D2937kj9PfungScOpx8LRZyYZSXsXteSXaqpDRCasyRfoTY/A8vsOckMli42OB0bM9acMHz0X+04ehgvG/FcQEcmGyRfopfUw85zhN1SKT3VMndSfOCIicqgmX/Id9/nYl4iIDKEFyiIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBIK9DNbJGZrTezjWb27ST7jzKzV8zsb2a2xswuzHypIiJyMCMGupmFgAeAC4B5wNVmNi+h213Ak865k4GrgJ9kulARETm4dEbopwMbnXObnHPdwBPA4oQ+Dij1tsuArZkrUURE0pFOoNcDm32PW7w2v38BrjGzFuB54JZkT2RmN5lZk5k1tbW1HUK5IiKSSqZOil4NPOqcawAuBP6PmQ17bufcUudco3OusaqqKkMvLSIikF6gbwGm+x43eG1+NwJPAjjnVgARoDITBYqISHrSCfQ3gNlmNtPM8oid9Hw2oc/HwN8DmNlcYoGuORURkTE0YqA753qBm4GXgGZiq1neNbPvmdklXrd/BJaY2VvA48B1zjmXraJFRGS43HQ6OeeeJ3ay09/2Xd/2WuCszJYmIiKjoStFRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEGkFupktMrP1ZrbRzL6dos9/NLO1Zvaumf0ys2WKiMhIckfqYGYh4AHgPKAFeMPMnnXOrfX1mQ38M3CWc26PmVVnq2AREUkunRH66cBG59wm51w38ASwOKHPEuAB59weAOfcjsyWKSIiI0kn0OuBzb7HLV6b33HAcWb2FzNbaWaLkj2Rmd1kZk1m1tTW1nZoFYuISFKZOimaC8wGFgJXA//LzKYkdnLOLXXONTrnGquqqjL00iIiAukF+hZguu9xg9fm1wI865zrcc59AGwgFvAiIjJG0gn0N4DZZjbTzPKAq4BnE/r8ltjoHDOrJDYFsymDdYqIyAhGDHTnXC9wM/AS0Aw86Zx718y+Z2aXeN1eAnaZ2VrgFeCfnHO7slW0iIgMZ865cXnhxsZG19TUNC6vLSIyWZnZKudcY7J9ulJURCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQmItALdzBaZ2Xoz22hm3z5Iv8vNzJlZY+ZKFBGRdIwY6GYWAh4ALgDmAVeb2bwk/UqAW4HXM12kiIiMLJ0R+unARufcJudcN/AEsDhJv+8D/wpEM1ifiIikKZ1Arwc2+x63eG1xZnYKMN0599zBnsjMbjKzJjNramtrG3WxIiKS2mGfFDWzHOC/Af84Ul/n3FLnXKNzrrGqqupwX1pERHzSCfQtwHTf4wavbUAJcALwqpl9CJwBPKsToyIiYyudQH8DmG1mM80sD7gKeHZgp3Ou3TlX6Zyb4ZybAawELnHONWWlYhERSWrEQHfO9QI3Ay8BzcCTzrl3zex7ZnZJtgsUEZH05KbTyTn3PPB8Qtt3U/RdePhliYjIaOlKURGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiATHpAn17R5T12/bS09c/3qWIiEwoueNdwGg9/eYW/vXFdeSFcphdU8y8ulLmel/z6kopKwyPd4kiIuNi0gX6xSfVUVcWobm1g7WtHbyyvo1fr2qJ759WFokHfOyrhBlTi8jJsXGsWkQk+yZdoDeUF9JQXsilJ9fH23bsjdLcupfm1o7416sb2ujrdwAUhEPMqS1h3rSBkXwJc2pLKc6fdL++iEhKgUi06pII1SURzjmuKt4W7elj4459rPWF/HNrWvnl6x/H+xw9tZC5tYMj+bl1pTSUF2Cm0byITD6BCPRkIuEQJ9SXcUJ9WbzNOcfW9ijNW72Q39ZBc+teXlq7DRcbzFMSyY3Pxw+E/HE1JUTCoXH6TURE0hPYQE/GzKifUkD9lAI+N68m3r6/q5f12wenbNZu7eDJps10dvcBkGMwq6p4yEh+fl0pVSX5Gs2LyIRxRAV6KkX5uZxyVDmnHFUeb+vvd3y8u3Mw5Fv38uZHe/jdW1vjfaYW5Q0J+bl1pRxTVUxe7qRbDSoiAaBATyEnx5hRWcSMyiIu+FRdvL39QA/rvBU2sbDfy89XfER3b2xdfDhkHFtdwty6EubFp25KKS/KG69fRUSOEAr0USorCPPpWVP59Kyp8bbevn4+2LnfC/nY1M2f39vJ029uifepLY0MGcnPrStlZmURIS2nFJEMUaBnQG4oh9k1JcyuKWHxgsH2nfu6fEspY0H/p/d20ustp4yEc5hTMxjy86aVcnxtCSURXRwlIqNnbmB5xxhrbGx0TU1N4/La46mrN7acciDg126Nrbb5pLMn3md6RYFvOWVs2mZ6hZZTigiY2SrnXGOyfRqhj7H83BDzp5Uxf9rQ5ZTbOqLxkfzA/PzLzdvjyymL83M5vrYkPpKfW1fKnJoSCvK0nFJEYjRCn8AOdPfFl1Ou9dbOr9u2l31dvUBsOeWMyqJh6+ZrSyMazYsE1GGP0M1sEfA/gBDwM+fcvQn7bwO+CvQCbcANzrmPDqtqoSAvxILpU1gwfUq8rb/f0bLnwJArYNe0fMJza1rjfaYUhplbOziSn1tXwrHVxeTnajQvEmQjjtDNLARsAM4DWoA3gKudc2t9fc4FXnfOdZrZPwALnXNXHux5NULPrI5oD+u37Y2P5JtbO1i/fS/Rnthyytwc49jq4mHr5iuL88e5chEZjcMdoZ8ObHTObfKe7AlgMRAPdOfcK77+K4FrDr1cORSlkTCnzajgtBkV8ba+fscHO/cPuWnZa+/v5Jm/DS6nrCrJHzJlM89bTpkb0sVRIpNNOoFeD2z2PW4BPn2Q/jcCLyTbYWY3ATcBHHXUUWmWKIcq5I3Kj60u5uKTpsXbd+/v9l0BGzsR+7/f30RPX+x/a/m5ORxXUzJs3XxZgZZTikxkGV3lYmbXAI3AOcn2O+eWAkshNuWSuL+np4eWlhai0WgmyzpiRCIRGhoaCIcPHrwVRXmcdWwlZx1bGW/r7u3n/bZ9Q9bNL2vewZNNg/ear59SEL/98EDIH1VRqHvNi0wQ6QT6FmC673GD1zaEmX0OuBM4xznXdSjFtLS0UFJSwowZM7RKY5Scc+zatYuWlhZmzpw56p/Py82Jh7T/OXfs7Rpym4Pm1g7+uG473rVRFOXF7jXvH8kfX1tCke41LzLm0vlb9wYw28xmEgvyq4D/5O9gZicDDwGLnHM7DrWYaDSqMD9EZsbUqVNpa2vL6HPWlEaoKY1w7pzqeHu0p48N2/0nYPfy7Oqt/Jt3r3kzmDG1KDZlM3CB1LRSppVpOaVINo0Y6M65XjO7GXiJ2LLFh51z75rZ94Am59yzwH1AMfBr7y/sx865Sw6lIP2FP3Rjdewi4RAnNkzhxIbB5ZTOxZZT+kfy727t4Pm3t8X7lBWEBy+O8i6QOra6WPeaF8mQtP5f7Jx7Hng+oe27vu3PZbgumWTMjOkVhUyvKOTz82vj7Xu95ZQDtyBubu3gV29s5kBP7F7zoRzjmKqiYZ8DW10SGa9fRWTS0kRnguLiYvbt2zfeZQRGSSRM44wKGhOWU360a/+Qz4F944Pd/N/Vg/earyzOw38vm7l1pcyqKiKs5ZQiKSnQZcyFcoxZVcXMqirmohMH7zX/SWf3kFsQN7d28OhfPqS7L3ZxVF4oh9k1xUNG8vPqSplSqHvNi8AEDvT/+rt3Wbu1I6PPOW9aKXdfPD+tvs45br/9dl544QXMjLvuuosrr7yS1tZWrrzySjo6Oujt7eWnP/0pZ555JjfeeCNNTU2YGTfccAPf/OY3M1r7kWBKYR5nHlPJmccMLqfs6etnU9t+35r5Dl5dv4OnVg0up6wri/gCvoy5dSUcPVX3mpcjz4QN9PH29NNPs3r1at566y127tzJaaedxtlnn80vf/lLzj//fO688076+vro7Oxk9erVbNmyhXfeeQeATz75ZJyrD45wKIc5tSXMqS3h0pPr4+079kaHjOSbWzv4fxva6PPWUxaEB5dTDqybP76ulGItp5QAm7Dv7nRH0tny5z//mauvvppQKERNTQ3nnHMOb7zxBqeddho33HADPT09XHrppSxYsIBZs2axadMmbrnlFi666CI+//nPj2vtR4LqkgjVJRHOOa4q3hbt6eO97fuGjOafW7OVx//aG+9zVEVhfE5+4ErYhnLda16CYcIG+kR19tlns3z5cp577jmuu+46brvtNr7yla/w1ltv8dJLL/Hggw/y5JNP8vDDD493qUecSDjEpxrK+FTD0HvNb22P0jywZn5bbI7+pbXb4veaL4nkeuvlB0fy9VMKmFqUp6tgZVJRoKfw2c9+loceeohrr72W3bt3s3z5cu677z4++ugjGhoaWLJkCV1dXbz55ptceOGF5OXlcfnllzNnzhyuuUb3JpsozIz6KQXUTyngc/Nq4u37u3pZt23olM2vV7XQ2d0X7xMOGdUlEWrLvK/SCHVlsQutBr7XlEbIy9XKG5kYFOgpfPGLX2TFihWcdNJJmBk//OEPqa2t5ec//zn33Xcf4XCY4uJiHnvsMbZs2cL1119Pf39sNcYPfvCDca5eRlKUn8upR5dz6tHl8bb+fsfHuztZv30v29qjbOuIxr63R1m7tYM/NG+P347Yr7I4Lx74g98LBh+XRTR3L2NiQn1iUXNzM3Pnzh2XeoJCxzB7nHN0HOilteNAPOjjoe/77v982AEl+bnUlMVG9v6g9/8jUFGUp7l8GZE+U1QkA8yMssIwZYVhjq8tTdnvQHcf2zuitLZHE74fYFtHFxu2t9G2tyt+g7MBebk51JTmU1daEA//moRpnuqSfN2rXlJSoItkWEFeiBmVRcyoLErZp7evn7Z9XUlH+q3tUda0fMJL70bp7h06xWMGVcX5Q0f3vu06b6pHHx5+ZFKgi4yD3FAOdWUF1JUVpOzjnGNPZ48X9AfY1t7FtvYD8dD/cNd+Vmzaxd5o77CfLSsIJ8zpDz+5W1YQ1hRPwCjQRSYoM6OiKI+KojzmTUs9xbO/q5dtHVG2t8eCPnFef21rBzv3dZF4uiw/N2fotE5ZhLp4+MdG+lUl+bridhJRoItMckX5uRxTVcwxVcUp+/T09bNjrzfCb++itf1AfH5/W3uUpo/2sL0jGv8YwgGhHItP8fjD3z/yrymN6BbIE4QCXeQIEA7lxNfjp9Lf79jd2R2f12/1jfq3d0TZsH0vyze0sd+3Vn9AeWHYG9Xnx0f38VG/F/qlkVxN8WSZAl1EAMjJMSqL86kszueE+rKU/fZGe4aM7hNP6q5paWfX/u5hP1eYF0o+r18aO5lbU5ZPZVG+rs49DAr0cdLb20turg6/TD4lkTAlkTDHVpek7NPV28eOjq74CVz/SL+1/QArN+1ix94uehPWbubmxD72cPiFWoPbujo3tYmbKC98G7a9ndnnrP0UXHDviN0uvfRSNm/eTDQa5dZbb+Wmm27ixRdf5I477qCvr4/Kykr+8Ic/sG/fPm655Zb4bXPvvvtuLr/88iEfkvHUU0/x+9//nkcffZTrrruOSCTC3/72N8466yyuuuoqbr31VqLRKAUFBTzyyCPMmTOHvr4+vvWtb/Hiiy+Sk5PDkiVLmD9/Pvfffz+//e1vAXj55Zf5yU9+wjPPPJPZYySSAfm5ofgnWKXS1+/Ytc8X+gnhH/tA8h3xT7fyqyzOG7ZGv8Yb6deWxaZ9jsSrc4+83zgNDz/8MBUVFRw4cIDTTjuNxYsXs2TJEpYvX87MmTPZvXs3AN///vcpKyvj7bdj//Ds2bNnxOduaWnhtddeIxQK0dHRwZ/+9Cdyc3NZtmwZd9xxB7/5zW9YunQpH374IatXryY3N5fdu3dTXl7O17/+ddra2qiqquKRRx7hhhtuyOpxEMmmUI5RXRqhujTCiQ3J+zjn6Ij2+qZ1vOWb3tW6LXsOsOqjPexJcnVucX5uwhr94RdqBe3q3Ikb6GmMpLPl/vvvj498N2/ezNKlSzn77LOZOXMmABUVsY9TW7ZsGU888UT858rLy4c/WYIrrriCUCi2IqC9vZ1rr72W9957DzOjp6cn/rxf+9rX4lMyA6/35S9/mV/84hdcf/31rFixgsceeyxDv7HIxGRmlBWEKSsIM6c29RRPtGf41bn+k7sb39vJjr3R4VfnhnKoKcv33X9n8KTuwDRPdUn+pPnow4kb6OPk1VdfZdmyZaxYsYLCwkIWLlzIggULWLduXdrP4f8XPxqNDtlXVDR49eB3vvMdzj33XJ555hk+/PBDFi5ceNDnvf7667n44ouJRCJcccUVmoMX8UTCIY6eWsTRUw9+de7Ofd1Dl2z6bsC2puUT/r09SleSq3Mri/OTjvD9wV+YN/5/H8e/ggmmvb2d8vJyCgsLWbduHStXriQajbJ8+XI++OCD+JRLRUUF5513Hg888AA//vGPgdiUS3l5OTU1NTQ3NzNnzhyeeeYZSkqSjyza29upr499Cs+jjz4abz/vvPN46KGHOPfcc+NTLhUVFUybNo1p06Zxzz33sGzZsqwfC5EgyQ3lxMM3Feccn3T2DLsVw3ZvpP/xrk5e37SLjiRX55ZGcr3VOrELtIbdjK00wpTC7F6dq0BPsGjRIh588EHmzp3LnDlzOOOMM6iqqmLp0qVcdtll9Pf3U11dzcsvv8xdd93FN77xDU444QRCoRB33303l112Gffeey9f+MIXqKqqorGxMX6CNNHtt9/Otddeyz333MNFF10Ub//qV7/Khg0bOPHEEwmHwyxZsoSbb74ZgC996Uu0tbXpjooiWWBmlBflUV6Ux9y61Ffndnb3Jr/bpre9rrWDthRX59aWRbjtvONYvKA++ZMfTv26fe7kcvPNN3PyySdz4403Jt2vYygyMQxenRsdelK3o4srG6fzmdmVIz9JErp9bkCceuqpFBUV8aMf/Wi8SxGREaRzdW6mKdAnkVWrVo13CSIygU24tTjjNQUUBDp2Ike2CRXokUiEXbt2KZgOgXOOXbt2EYmkPoMvIsE2oaZcGhoaaGlpoa2tbbxLmZQikQgNDSkuuRORwJtQgR4Oh+NXY4qIyOhMqCkXERE5dAp0EZGAUKCLiATEuF0pamZtwEeH+OOVwM4MlpMpqmt0VNfoTdTaVNfoHE5dRzvnqpLtGLdAPxxm1pTq0tfxpLpGR3WN3kStTXWNTrbq0pSLiEhAKNBFRAJisgb60vEuIAXVNTqqa/Qmam2qa3SyUteknEMXEZHhJusIXUREEijQRUQCYsIFupktMrP1ZrbRzL6dZH++mf3K2/+6mc3w7ftnr329mZ0/xnXdZmZrzWyNmf3BzI727eszs9Xe17NjXNd1Ztbme/2v+vZda2bveV/XjnFd/91X0wYz+8S3L5vH62Ez22Fm76TYb2Z2v1f3GjM7xbcvK8crjZq+5NXytpm9ZmYn+fZ96LWvNrOmZD+f5doWmlm778/ru759B30PZLmuf/LV9I73nqrw9mXlmJnZdDN7xcuBd83s1iR9svv+cs5NmC8gBLwPzALygLeAeQl9vg486G1fBfzK257n9c8HZnrPExrDus4FCr3tfxioy3u8bxyP13XA/0zysxXAJu97ubddPlZ1JfS/BXg428fLe+6zgVOAd1LsvxB4ATDgDOD1MTheI9V05sBrARcM1OQ9/hCoHMfjtRD4/eG+BzJdV0Lfi4E/ZvuYAXXAKd52CbAhyd/HrL6/JtoI/XRgo3Nuk3OuG3gCWJzQZzHwc2/7KeDvzcy89iecc13OuQ+Ajd7zjUldzrlXnHOd3sOVwFjcxzad45XK+cDLzrndzrk9wMvAonGq62rg8Qy99kE555YDuw/SZTHwmItZCUwxszqyeLxGqsk595r3mjB2762B1x7peKVyOO/NTNc1Ju8v51yrc+5Nb3sv0AwkfhJ0Vt9fEy3Q64HNvsctDD8g8T7OuV6gHZia5s9msy6/G4n9KzwgYmZNZrbSzC7NUE2jqety7793T5nZ9FH+bDbrwpuamgn80decreOVjlS1Z/N4jUbie8sB/25mq8zspnGoB+A/mNlbZvaCmc332ibE8TKzQmLB+Btfc9aPmcWmgk8GXk/YldX314S6H3oQmNk1QCNwjq/5aOfcFjObBfzRzN52zr0/RiX9DnjcOddlZv+Z2P9u/m6MXjsdVwFPOef6fG3jebwmLDM7l1igf8bX/BnvWFUDL5vZOm/0OlbeJPbntc/MLgR+C8wew9cfycXAX5xz/tF8Vo+ZmRUT+wfkvzjnOjL1vOmYaCP0LcB03+MGry1pHzPLBcqAXWn+bDbrwsw+B9wJXOKc6xpod85t8b5vAl4l9i/3mNTlnNvlq+VnwKnp/mw26/K5ioT/DmfxeKUjVe3ZPF4jMrMTif35LXbO7Rpo9x2rHcAzZG6aMS3OuQ7n3D5v+3kgbGaVjPPx8jnY+yvjx8zMwsTC/N+cc08n6ZLd91emTwwc5kmFXGInA2YyeCJlfkKfbzD0pOiT3vZ8hp4U3UTmToqmU9fJxE4CzU5oLwfyve1K4D0ydHIozbrqfNtfBFa6wZMwH3j1lXvbFWNVl9fveGInqGwsjpfvNWaQ+iTfRQw9afXXbB+vNGo6itg5oTMT2ouAEt/2a8CiTB6rNGqrHfjzIxaMH3vHLq33QLbq8vaXEZtnLxqLY+b93o8BPz5InxlTUwoAAADxSURBVKy+vzL6B5+hg3IhsbPD7wN3em3fIzbqBYgAv/be4H8FZvl+9k7v59YDF4xxXcuA7cBq7+tZr/1M4G3vDf02cOMY1/UD4F3v9V8Bjvf97A3ecdwIXD+WdXmP/wW4N+Hnsn28HgdagR5i85Q3Al8DvubtN+ABr+63gcZsH680avoZsMf33mry2md5x+kt78/4zkweqzRru9n3/lqJ7x+dZO+BsarL63MdsYUS/p/L2jEjNhXmgDW+P6sLx/L9pUv/RUQCYqLNoYuIyCFSoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAuL/A+E2h+3bA6DiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmelmbSGYr31"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hoUut0ZNMMJ"
      },
      "source": [
        "outputs = model.predict(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byyOfqhZ1_lq",
        "outputId": "a0da8ef0-405b-4b60-c196-aa5815b65226"
      },
      "source": [
        "outputs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.56885725,  0.53636175],\n",
              "        [-2.1566873 ,  1.9645814 ],\n",
              "        [-0.17893487,  0.328328  ],\n",
              "        ...,\n",
              "        [-0.1108906 ,  0.17399508],\n",
              "        [-0.1108906 ,  0.17399508],\n",
              "        [-0.1108906 ,  0.17399508]], dtype=float32),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C0___HCe6aC"
      },
      "source": [
        "tf_predictions = tf.nn.sigmoid(output[0])\n",
        "tf_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYdxmigLfBpI"
      },
      "source": [
        "#predictions = tf.argmax(tf_predictions, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xSL4UQ92CAd",
        "outputId": "5dd33eb2-52cf-439f-dc4c-336ad5365bdf"
      },
      "source": [
        "preds = tf.argmax(outputs[0], axis = 1)\n",
        "preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p6F9MiU2CLx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nARDedck2CPb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF3uKdpc2CTw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP2yTIoFZPjR"
      },
      "source": [
        "# With Native Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "HNBvK_ZwNMOw",
        "outputId": "6e261300-d9e3-4784-cdbf-012a928b3796"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import DistilBertForSequenceClassification, AdamW\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "train_loader = DataLoader(train_dataset_torch, batch_size=16, shuffle=True)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(3):\n",
        "    for batch in train_loader:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-3089d4689379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distilbert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrmcf8dBNMQ8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1T22FzgNMTc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LzLYuqCNMV7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87TqZOqMNMY_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6nN9_-9NMbP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQDKGKEgNMdu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}